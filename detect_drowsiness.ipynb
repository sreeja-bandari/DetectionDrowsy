{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Drowsiness Detection OpenCV\n\n\nThis code can detect your eyes and alert when the user is drowsy.\n\n## Applications\nThis can be used by riders who tend to drive for a longer period of time that may lead to accidents.\n\n### Algorithm\n\nEach eye is represented by 6 (x, y)-coordinates, starting at the left-corner of the eye (as if you were looking at the person), and then working clockwise around the eye:.\n\n<img src=\"eye1.jpg\">\n\n### Condition\n\nIt checks 20 consecutive frames and if the Eye Aspect ratio is lesst than 0.25, Alert is generated.\n\n#### Relationship\n\n<img src=\"eye2.png\">\n\n#### Summing up\n\n<img src=\"eye3.jpg\">\n\nJupiter Kernel",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"left_eye\"]\n(rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS[\"right_eye\"]",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "from scipy.spatial import distance\nfrom imutils import face_utils\nimport imutils\nimport dlib\nimport cv2",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "def eye_aspect_ratio(eye):\n\tA = distance.euclidean(eye[1], eye[5])\n\tB = distance.euclidean(eye[2], eye[4])\n\tC = distance.euclidean(eye[0], eye[3])\n\tear = (A + B) / (2.0 * C)\n\treturn ear",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "thresh = 0.25\nframe_check = 20\ndetect = dlib.get_frontal_face_detector()\npredict = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "cap=cv2.VideoCapture(0)\nflag=0\nwhile True:\n\tret, frame=cap.read()\n\tframe = imutils.resize(frame, width=450)\n\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n\tsubjects = detect(gray, 0)\n\tfor subject in subjects:\n\t\tshape = predict(gray, subject)\n\t\tshape = face_utils.shape_to_np(shape)#converting to NumPy Array\n\t\tleftEye = shape[lStart:lEnd]\n\t\trightEye = shape[rStart:rEnd]\n\t\tleftEAR = eye_aspect_ratio(leftEye)\n\t\trightEAR = eye_aspect_ratio(rightEye)\n\t\tear = (leftEAR + rightEAR) / 2.0\n\t\tleftEyeHull = cv2.convexHull(leftEye)\n\t\trightEyeHull = cv2.convexHull(rightEye)\n\t\tcv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1)\n\t\tcv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1)\n\t\tif ear < thresh:\n\t\t\tflag += 1\n\t\t\t#print (flag)\n\t\t\tif flag >= frame_check:\n\t\t\t\tcv2.putText(frame, \"****************ALERT!****************\", (10, 30),\n\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n\t\t\t\tcv2.putText(frame, \"****************ALERT!****************\", (10,325),\n\t\t\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n\t\telse:\n\t\t\tflag = 0\n\tcv2.imshow(\"Frame\", frame)\n\tkey = cv2.waitKey(1) & 0xFF\n\tif key == ord(\"q\"):\n\t\tcv2.destroyAllWindows()\n\t\tcap.release()\n\t\tbreak\n",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}